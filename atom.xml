<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小花猫</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://lhy.io/"/>
  <updated>2017-01-16T15:57:00.000Z</updated>
  <id>https://lhy.io/</id>
  
  <author>
    <name>meow</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>谷歌／Waymo 无人车小知识</title>
    <link href="https://lhy.io/GoogleSDC/"/>
    <id>https://lhy.io/GoogleSDC/</id>
    <published>2017-01-14T14:44:34.000Z</published>
    <updated>2017-01-16T15:57:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>谷歌的无人驾驶汽车项目已经从谷歌分离出来成为 Alphabet 的子公司 Waymo 了，不过成果基本上还是作为谷歌无人车的时候实现的。我们可以先看一下无人车的这两种车型。</p>
<img src="/GoogleSDC/001.jpeg" alt="001.jpeg" title="">
<p>这是原型车（prototype vehicle）。</p>
<img src="/GoogleSDC/002.jpeg" alt="002.jpeg" title="">
<p>这是 Chrysler Pacifica Hybrid，谷歌之前用的是 Lexus RX450h SUV。</p>
<a id="more"></a>
<p>无人驾驶汽车是一个复杂的软硬件系统，它涉及到的技术和方法不是能简单概括的，很多内容不作为内部的技术人员很难准确的知道和理解的。不过，谷歌和 Waymo 开放了许多资料和视频，我们还是能从中得知他们团队对无人车的思考以及使用或可能使用的技术。</p>
<p>谷歌的无人车使用了三种主要的传感器 ：摄像头（cameras），激光雷达（lidars）和 测距雷达（radars） 。激光雷达（lidars）就是那种很贵的，价格可高达几十万，能够用来形成周围物体的三维特征。雷达（radars）与普通汽车上的倒车雷达类似，用来探测前面的车的距离和车速。</p>
<img src="/GoogleSDC/003.png" alt="003.png" title="">
<p>那么我就从我查到的资料来简单的举一些典型或者有意思的例子来说明谷歌设计无人车时的思路和方法：</p>
<h3 id="1-为无人车建立专属地图（BUILDING-MAPS-FOR-A-SELF-DRIVING-CAR-report0316）"><a href="#1-为无人车建立专属地图（BUILDING-MAPS-FOR-A-SELF-DRIVING-CAR-report0316）" class="headerlink" title="1. 为无人车建立专属地图（BUILDING MAPS FOR A SELF-DRIVING CAR - report0316）"></a>1. 为无人车建立专属地图（BUILDING MAPS FOR A SELF-DRIVING CAR - report0316）</h3><p>谷歌会为他的无人车建造地图，和我们使用的谷歌地图或者高德地图的 app 不同，无人车使用的地图会包含更多的信息，如路缘的高度，十字路口的宽度，交通标志、红绿灯的高度和准确位置等信息。</p>
<p>这些地图信息不是无人车在行驶的过程中自己生成的，当谷歌的无人车将要进入一个新的环境测试的时候，他们会开着自己的无人车用车上的激光雷达收集周围环境的三维数据，之后会对这些数据进行标定和分类，比如道路线的状态，路灯高度，路边的消防栓等。</p>
<p>这么做的好处是无人车在真正上路的时候能够知道自己在什么样的位置时会遇到什么东西，也能更专注于处理移动的目标，比如行驶的车辆和行人等，还有本不该出现的障碍物等，还可以减少路面永久性（这里的永久指长时间不会改变）的物体对无人车真正上路进行识别定位其它车辆、行人、障碍物时的干扰。</p>
<img src="/GoogleSDC/004.png" alt="004.png" title="">
<h3 id="2-鸣笛算法（Honking-Algorithms-report-0516）"><a href="#2-鸣笛算法（Honking-Algorithms-report-0516）" class="headerlink" title="2. 鸣笛算法（Honking Algorithms - report 0516）"></a>2. 鸣笛算法（Honking Algorithms - report 0516）</h3><p>如果一辆车突然转进自己的车道，我们是不是应该提醒它一下“喂！你后面还有车呢！”？谷歌就为自己的无人车设计了鸣笛算法用来提醒其他司机注意自己的存在。虽然被鸣笛提醒往往是一种不好的体验，不过谷歌希望它的无人车的鸣笛算法是礼貌且细心周到的，并且只在鸣笛能够让大家更安全的情况下进行。</p>
<p>谷歌希望教会无人车区分真正需要鸣笛的情景和看起来需要但是并不需要的情景，比如车在掉头的时候你需要等待而不是鸣笛，但是车跑在了错误的车道时候你可能就需要鸣笛提醒。在进行鸣笛算法测试的时候，谷歌会让测试驾驶员记录无人车每一次鸣笛的情况以帮助工程师优化算法。</p>
<img src="/GoogleSDC/005.png" alt="005.png" title="">
<h3 id="3-谷歌无人车的三点掉头（THE-THREE-POINT-TURN）"><a href="#3-谷歌无人车的三点掉头（THE-THREE-POINT-TURN）" class="headerlink" title="3.  谷歌无人车的三点掉头（THE THREE-POINT TURN）"></a>3.  谷歌无人车的三点掉头（THE THREE-POINT TURN）</h3><p>谷歌希望无人车能够给人提供到位的服务，你出家门就可以坐到车它能够把你直接送到公司门口或者胡同里聚会的小酒吧门口。所以三点掉头是无人车必须要掌握的技能。</p>
<p>三点掉头指的是从马路的最右侧做回转，当接触到最左侧的路沿时做后退动作，同时在后退时继续将车头进行调整，最后换成前进档，继续完成掉头动作。人在进行三点掉头的时候会使车子向前向后多次移动来观察整个路况然后调整角度和距离来掉头，不过无人车有360度的视角，能够计算出最短最快路径，如下图的紫色和绿色的细线（途中紫色的方块是障碍物）。不过无人车并没有这么做，为了给车上的乘客感觉起来更舒适，谷歌选择教无人车模仿人掉头的方式，如下图中宽的车道。</p>
<img src="/GoogleSDC/006.png" alt="006.png" title="">
<h3 id="4-试图理解其他移动物体的目的（Understanding-other-Vehicles’-intention）"><a href="#4-试图理解其他移动物体的目的（Understanding-other-Vehicles’-intention）" class="headerlink" title="4. 试图理解其他移动物体的目的（Understanding other Vehicles’ intention）"></a>4. 试图理解其他移动物体的目的（Understanding other Vehicles’ intention）</h3><p>谷歌的无人车会根据其他的车或行人已经作出的一些行为或指示来预测这个车将要做什么，比如下图中无人车依据右前方的这个车的一些微小的位移等预测它将要变道到自己的车道上来，于是无人车减速配合其顺利变道。</p>
<img src="/GoogleSDC/007.png" alt="007.png" title="">
<p>又比如下面这张图片中，无人车探测到在它前方的自行车手（红色方框标出）的手势可能是要到马路对面去，于是减速留出足够的空间让自行车顺利通过。</p>
<img src="/GoogleSDC/008.png" alt="008.png" title="">
<p>以上的内容希望能对大家理解谷歌的无人车有所帮助。无人车要应对的场景繁多且复杂，有一些可以写成固定的算法，比如三点掉头的方法，面对信号灯或交通标志的行为；还有一些从未遇到的场景可能就需要像上面那样试图预测移动物体的下一步行为，比如一只过马路的狗狗。</p>
<p>谷歌在它的无人车月度报告中多次使用了【taught】这个词，几乎可以肯定很多重要的算法都是基于深度学习的。最后大家可以看这一段来自 Waymo 官网的<a href="http://www.bilibili.com/video/av8013176/" target="_blank" rel="external">视频</a>，感受一下这些算法在实际中的应用。</p>
<p>参考资料及所有图片来源：</p>
<ul>
<li>Waymo 官网</li>
<li>Waymo Medium Blog</li>
<li>Google Self-Driving Car Project Monthly Report</li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;谷歌的无人驾驶汽车项目已经从谷歌分离出来成为 Alphabet 的子公司 Waymo 了，不过成果基本上还是作为谷歌无人车的时候实现的。我们可以先看一下无人车的这两种车型。&lt;/p&gt;
&lt;img src=&quot;/GoogleSDC/001.jpeg&quot; alt=&quot;001.jpeg&quot; title=&quot;&quot;&gt;
&lt;p&gt;这是原型车（prototype vehicle）。&lt;/p&gt;
&lt;img src=&quot;/GoogleSDC/002.jpeg&quot; alt=&quot;002.jpeg&quot; title=&quot;&quot;&gt;
&lt;p&gt;这是 Chrysler Pacifica Hybrid，谷歌之前用的是 Lexus RX450h SUV。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Self-driving Car" scheme="https://lhy.io/tags/Self-driving-Car/"/>
    
  </entry>
  
  <entry>
    <title>搭建一个简单的识别印刷体数字的分类器</title>
    <link href="https://lhy.io/digit_recognition/"/>
    <id>https://lhy.io/digit_recognition/</id>
    <published>2017-01-01T14:44:34.000Z</published>
    <updated>2017-01-03T16:26:45.000Z</updated>
    
    <content type="html"><![CDATA[<p>对于很多机器学习和深度学习的初学者来说，数字识别是一个非常棒的学习和练手项目。我将在这篇文章中介绍搭建一个识别印刷体数字的分类器的思路和方法并附上完整可运行的代码。</p>
<p>这是一个识别印刷体数字的分类器，我们输入的是一张含有数字的图片，经过分类器的分析处理，我们能够框出图片上的数字并识别。比如这样：</p>
<img src="/digit_recognition/test1111.png" alt="test1111.png" title="">
<a id="more"></a>
<p>当功能确定以后，我们就需要为分类器设计一个神经网络模型，寻找一个合适的数据集对模型进行训练，然后验证模型的准确性，最后我们还可以在各种平台应用这个模型。</p>
<p>在这个问题中，我们使用的是简单的多层神经网络，结构如下图：</p>
<img src="/digit_recognition/结构.png" alt="结构.png" title="">
<p>我们对其输入的是一个 28*28 的图片，经过 flatten 转换成784个数据点作为输入。这个模型含有两个隐藏层，每个隐藏层有512个神经元。784个数据点输入以后，经过两个隐藏层运算后就输出成了11个类的概率。这11个类包含0～9十个数字和一个非数字类，概率最大的那个就是我们的预测结果。</p>
<h3 id="1-数据集的选择和预处理"><a href="#1-数据集的选择和预处理" class="headerlink" title="1.数据集的选择和预处理"></a>1.数据集的选择和预处理</h3><p>我们选择的数据集来自英国萨里大学的<a href="http://www.ee.surrey.ac.uk/CVSSP/demos/chars74k/" target="_blank" rel="external">网站</a>。这个网站提供了多种英文字母数字的数据集，有来自生活场景的，也有电脑印刷体的。我们选择的是<strong>EnglishFnt.tgz</strong>，这个数据集包含了印刷体数字和字母的60000+的样本。</p>
<img src="/digit_recognition/数据集预览.png" alt="数据集预览.png" title="">
<center>数据集预览</center>

<p>在这个项目中，我们选择了用程序自动下载和自动解压的方法，这个过程也可以手动完成。</p>
<blockquote>
<p>在这里强烈给大家推荐tqdm这个库，<a href="https://github.com/tqdm/tqdm" target="_blank" rel="external">tqdm</a> 是阿拉伯语，意为“进度”。使用这个库我们可以在下载，处理以及训练等需要耗费较多时间的程序中加入进度条，直观的看到需要花费的时间以及进度。</p>
</blockquote>
<p>大家可以去解压后的目录 <em>/English/Fnt/</em> 下查看解压后的数据集，由于数据集中包含 <strong>0～9</strong> 10个数字 以及 <strong>A～Z</strong> 26个字母的大小写,所以会有Sample001～Sample062，共62个文件夹。</p>
<img src="/digit_recognition/解压后.png" alt="解压后.png" title="">
<p>数据集中包含 <strong>0～9</strong> 十个数字 以及 <strong>A～Z</strong> 26个字母的大小写，但是我们最后的分类器会分11个类，<strong>0～9</strong> 每个数字一类以及一个非数字类。非数字类就是 <strong>A～Z</strong> 26个字母的大小写，我们需要将这些文件移到同一个文件夹中。在这里，我们将 A~Z, a~z 的图片移到 Sample011 中，再将其他空文件夹删除。</p>
<img src="/digit_recognition/分类后.png" alt="分类后.png" title="">
<center>重新分类后的数据集</center>

<h3 id="2-数据集中图片的预处理"><a href="#2-数据集中图片的预处理" class="headerlink" title="2.数据集中图片的预处理"></a>2.数据集中图片的预处理</h3><p>对于图片的预处理过程取决于我们采用的模型，在这个项目中，我们模型的输入是28*28的灰度图片。于是，我们把这两个步骤写成了两个函数，使用resize(rawimg)来调整图片大小，使用convert(imgpath)将图片调成灰度。</p>
<img src="/digit_recognition/处理.png" alt="处理.png" title="">
<center>处理前 Vs. 处理后</center>

<h3 id="3-分离验证集"><a href="#3-分离验证集" class="headerlink" title="3.分离验证集"></a>3.分离验证集</h3><p>分离验证集的时候，我们使用的是机器学习库sklearn的train<br>_test_split，将数据集中90%的内容作为训练集，10%的内容作为验证集。</p>
<h3 id="4-图片生成器"><a href="#4-图片生成器" class="headerlink" title="4.图片生成器"></a>4.图片生成器</h3><p>在进行训练的时候，由于训练集往往会包含几万张图，所以我们通常不会选择将所有训练集的图片加载到内存当中而是选择使用图片生成器<a href="http://keras-cn.readthedocs.io/en/latest/preprocessing/image/" target="_blank" rel="external">ImageDataGenerator</a>。使用图片生成器生成一个batch的图像数据，支持实时数据提升。训练时该函数会无限生成数据，直到达到规定的epoch次数为止。</p>
<h3 id="5-模型搭建和训练"><a href="#5-模型搭建和训练" class="headerlink" title="5.模型搭建和训练"></a>5.模型搭建和训练</h3><p>有了图像生成器之后我们就可以搭建我们的模型了，由于我们的模型结构十分简单784-&gt;512-&gt;512-&gt;11，再加上人性化的keras， 不出20行就可以搞定。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">model = Sequential()</div><div class="line">model.add(Flatten(input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)))</div><div class="line">model.add(Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">model.add(Dense(<span class="number">512</span>, activation=<span class="string">'relu'</span>))</div><div class="line">model.add(Dropout(<span class="number">0.2</span>))</div><div class="line">model.add(Dense(<span class="number">11</span>))</div><div class="line">model.add(Activation(<span class="string">'softmax'</span>))</div><div class="line"></div><div class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</div><div class="line">              optimizer=<span class="string">'adadelta'</span>,</div><div class="line">              metrics=[<span class="string">'accuracy'</span>])</div><div class="line"></div><div class="line">model.summary()</div></pre></td></tr></table></figure>
<p>而且我们也可以通过代码清晰的看到我们的网络结构。</p>
<img src="/digit_recognition/网络结构.png" alt="网络结构.png" title="">
<p>只需要训练10代，valid accuracy 就可以达到95%以上。</p>
<h3 id="6-使用模型进行预测"><a href="#6-使用模型进行预测" class="headerlink" title="6.使用模型进行预测"></a>6.使用模型进行预测</h3><p>最后，使用模型进行预测也是很重要的部分。我们输入的是一张含有数字的普通图片，我们需要将图片转灰度，自适应二值化，提取轮廓，寻找最小矩形边界，判断是否满足预设条件，如宽、高，宽高比。将满足条件的图片缩放至最大边长为28的小图，然后将其放入一个28*28的白色图像的中心位置。将处理好的图片送入模型中运算，得到识别的结果。</p>
<img src="/digit_recognition/img1.png" alt="img1.png" title="">
<p>我们可以将我们训练好的模型应用到网页端或者某个app中。印刷数字识别的应用是非常广泛的，比如我们可以用它来识别车牌号，门牌号，快递单号（虽然通常的方法是扫描条形码😢）等。</p>
<p>我们的应用方法是将这个模型嵌入到了微信后台中，你可以在后台中回复一张图片，由于我们的模型简单，预处理方法也较为简单，所以发送的图片像素不要过大或者过小，白底黑字效果较好。可以尝试保存下面两张图的原图进行测试，发送时记得点<strong>预览</strong>并选择<strong>原图</strong>发送。</p>
<img src="/digit_recognition/matrix.png" alt="matrix.png" title="">
<img src="/digit_recognition/test.png" alt="test.png" title="">
<p>🔗完整的代码戳<a href="https://github.com/ypwhs/wechat_digit_recognition" target="_blank" rel="external">GitHub</a>即可下载。<br>🔗主要包含两部分：</p>
<ul>
<li><a href="https://github.com/ypwhs/wechat_digit_recognition/blob/master/Preprocessing%20dataset.ipynb" target="_blank" rel="external">Preprocessing dataset.ipynb</a></li>
<li><a href="https://github.com/ypwhs/wechat_digit_recognition/blob/master/Training%20Model.ipynb" target="_blank" rel="external">Training Model.ipynb</a></li>
</ul>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对于很多机器学习和深度学习的初学者来说，数字识别是一个非常棒的学习和练手项目。我将在这篇文章中介绍搭建一个识别印刷体数字的分类器的思路和方法并附上完整可运行的代码。&lt;/p&gt;
&lt;p&gt;这是一个识别印刷体数字的分类器，我们输入的是一张含有数字的图片，经过分类器的分析处理，我们能够框出图片上的数字并识别。比如这样：&lt;/p&gt;
&lt;img src=&quot;/digit_recognition/test1111.png&quot; alt=&quot;test1111.png&quot; title=&quot;&quot;&gt;
    
    </summary>
    
    
      <category term="Deep Learning" scheme="https://lhy.io/tags/Deep-Learning/"/>
    
  </entry>
  
  <entry>
    <title>ResNet-50 for Cats vs. Dogs</title>
    <link href="https://lhy.io/ResNet-50-for-Cats-vs-Dogs/"/>
    <id>https://lhy.io/ResNet-50-for-Cats-vs-Dogs/</id>
    <published>2016-12-13T13:03:46.000Z</published>
    <updated>2016-12-27T16:15:47.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Machine-Learning-Capstone-Project"><a href="#Machine-Learning-Capstone-Project" class="headerlink" title="Machine Learning Capstone Project"></a>Machine Learning Capstone Project</h1><h3 id="I-Definition"><a href="#I-Definition" class="headerlink" title="I. Definition"></a>I. Definition</h3><h3>Project Overview</h3>

<p>Cats and dogs are the most favorite pets in a human’s life, therefore, we always have photos containing cats or dogs in our albums. Sometimes we try to classify these photos into categories. What if we do these things automatically rather than by our own hands or eyes? With the technology of computer vision, the knowledge of machine learning or more precisely deep learning, these problems can be solved.</p>
<p>Many people have tried different ways to solve this problem and submitted their results on kaggle. Most of them really did very good jobs while some are not so satisfied.</p>
<p>In this project, I built a classifier trained by the dataset downloaded from kaggle. The dataset contains a large amount of ordinary daily images including cats or dogs. The classifier runs on the Jupyter Notebook.</p>
<p>$accuracy = \frac{n}{N}*100\%$</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Machine-Learning-Capstone-Project&quot;&gt;&lt;a href=&quot;#Machine-Learning-Capstone-Project&quot; class=&quot;headerlink&quot; title=&quot;Machine Learning Capstone 
    
    </summary>
    
    
      <category term="Machine Learning" scheme="https://lhy.io/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>顺丰家的狗🐶</title>
    <link href="https://lhy.io/%E9%A1%BA%E4%B8%B0%E5%AE%B6%E7%9A%84%E7%8B%97%F0%9F%90%B6/"/>
    <id>https://lhy.io/顺丰家的狗🐶/</id>
    <published>2016-06-11T09:42:41.000Z</published>
    <updated>2016-12-27T16:18:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>学校有个顺丰快递点，住着一个老太太，养了两只狗狗。</p>
<a id="more"></a>
<p>一只老狗，长得丑，矮胖，从前是流浪的，和学校其他的流浪狗一样。老太太从前喂了学校里好多流浪狗，但是这些流浪狗喂着喂着，换了一批又一批，有的在外面出车祸死了，有的被保安赶走或者打死了，有的狗不甘平凡，去远方流浪了。可是这只狗，一直都跟着老太太，从我来到这里开始，直到我离开的时候也是。大概是从小就流浪的原因，在外面吃了不苦头。老狗很怕人，即使是给她肉吃的人。从前，我去取快递的时候，看她一眼，她都会嘴里呜噜着，但不敢叫出来，躲得老远。</p>
<p>半年以前，顺丰家又来了一只小小狗，不知是哪家生了抱来的。特别小，小得好像一个手掌就能包起来，简直就是一个毛茸茸的肉球球。它看起来像是泰迪和一只黑土狗的串串，事实也是这样的。但是它也丑，因为它全身乌黑乌黑的，它不只是一个毛茸茸的肉球球，更是一个黑煤球！不过这一点关系也没有，因为它小，长得丑也是惹人爱的的，况且学校里没有更小的狗或者说没有别的狗了，所以更没有能和他争宠的了。自打它来到这里开始，就集万千宠爱于一身，它见到任何人都会屁颠屁颠的跑过去，拼尽全力摇尾巴。大家来取快递的时候都会被它逗笑，然后给它买肉肠吃，大家都知道它最喜欢的是王中王。</p>
<p><img src="/images/xiaohei.jpg" width="360px"></p>
<p style="text-align: center">(诺～就是这只小黑～)</p>

<p>后来小小狗长大了，长成了一只健壮的狗，已经开始满校园撒欢，走在路上能赚到好多王中王。它还是最受欢迎的，在路上看到人就会开心的奔过去，闻一闻，站起来或者坐下，亲热一番，再换一个路人，看看有没有给它肉肠的，它有时吃到撑吐，真的是毫不夸张。而老狗还是在顺丰家的屋子里，或者门口，从不走远。还是不敢接近任何人，除了老太太。但是它常常能沾小小狗的光，吃到肉肠。</p>
<p>一只狗，因为从小就生活在健康的环境里，受尽宠爱，赞美，夸奖，从不必担心明天，不必担心缺吃少穿，长大后也是乐观，开朗，善良，慷慨的；一只狗，从小在外流浪，历经风雨，曾被欺负和嫌弃，即使找到了依靠，内心还是胆怯，羞涩，难以建立信任，害怕被伤害。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;学校有个顺丰快递点，住着一个老太太，养了两只狗狗。&lt;/p&gt;
    
    </summary>
    
    
      <category term="🐶" scheme="https://lhy.io/tags/%F0%9F%90%B6/"/>
    
  </entry>
  
  <entry>
    <title>感冒心得</title>
    <link href="https://lhy.io/%E6%84%9F%E5%86%92%E5%BF%83%E5%BE%97/"/>
    <id>https://lhy.io/感冒心得/</id>
    <published>2015-11-11T09:45:41.000Z</published>
    <updated>2016-12-27T16:16:58.000Z</updated>
    
    <content type="html"><![CDATA[<p><strong>我只是一枚大学生，不是医学专业，医学知识仅限于个人常识，网络信息和多次生病观察及问医的经验，此文仅供参考不能作为用药标准，生病一定要第一时间去正规医院，尤其是老人儿童孕妇等。</strong><br><a id="more"></a><br>感冒在中医分为风热感冒和风寒感冒。</p>
<p><strong>风热感冒</strong>的表现为：<br>发热重、微恶风、头胀痛、<strong>有汗</strong>、咽喉红肿疼痛、咳嗽、痰黏或黄、鼻塞黄涕、咽红干痛。</p>
<p><strong>风寒感冒</strong>的表现为：<br>恶寒重，发热轻，无汗，<strong>头痛</strong>，鼻塞，流清涕，喉痒咳嗽。</p>
<p><strong>主要区判断方法：鼻涕是清鼻涕还是黄鼻涕，是否多汗。</strong></p>
<p>风寒感冒和风热感冒都可以吃常规的中成药，也就是感冒冲剂，伴有炎症的话再使用抗生素。但要判断自己是风寒感冒或风热感冒，对症用药才能有效果。</p>
<p>我风热发烧时喝几次清开灵基本就好了，从来没有经历过风寒感冒。</p>
<p><strong>在西医中感冒常分为病毒性和细菌性的</strong>，但是又有说法是没有所谓细菌性的感冒，所有感冒都是病毒引起的，感冒后由于抵抗力下降可能会导致细菌感染。</p>
<p>正确的判断方法只能通过查血常规，而且正规医院的血常规十多分钟就可以出结果，我去过的最贵的收费50RMB，一般情况下十几二十块就差不多了，所以，也不要觉得小病医生要查血拍片就是医院坑钱了，这是低成本又靠谱的方法，有医保就更好啦～</p>
<p><strong>纯病毒性的感冒</strong>不需要特别的治疗，主要是多喝热水，好好休息，补充维生素和无机盐，高烧有时会到四十一二度，傍晚起烧，一般连续一周左右，但是每天的最高体温都会降低，体温高于38度时可以用退烧药控制。</p>
<p><strong>带有细菌的感冒</strong>就必须对症服用抗生素，遵医嘱。</p>
<p>还有的只有打喷嚏流鼻涕的症状，很像感冒，但实际是<strong>过敏</strong>。医生给开过新康泰克。新康泰克是西药，含有伪麻黄碱，一般都会限购，对于打喷嚏流鼻涕（过敏或者感冒引起的）作用显著－大概半小时内就好，药效6个小时左右，治标不治本的。所以还服用过抗过敏药。</p>
<p>超过三天没有好转的病情就一定要去正规的医院！<br>亲身经历证明，即使是感冒发烧这种最普通的每个人都会有的病，有的医院也是真的很不靠谱，所以尽可能去三甲医院，并且信任自己的医生，谨遵医嘱！</p>
<p>去医院挂号的时候，如果发热就挂发热门诊有的也可以挂急诊，如果不发热可以尝试挂呼吸门诊，也可以去大厅的服务台或者分诊台问询。有条件去医院的话一定要去医院，尤其是有医保的人们去医院花费很少还能得到医生正确的治疗。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;我只是一枚大学生，不是医学专业，医学知识仅限于个人常识，网络信息和多次生病观察及问医的经验，此文仅供参考不能作为用药标准，生病一定要第一时间去正规医院，尤其是老人儿童孕妇等。&lt;/strong&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="🐶" scheme="https://lhy.io/tags/%F0%9F%90%B6/"/>
    
  </entry>
  
  <entry>
    <title>instaBTBU宣传图</title>
    <link href="https://lhy.io/instaBTBU/"/>
    <id>https://lhy.io/instaBTBU/</id>
    <published>2015-08-11T07:37:28.000Z</published>
    <updated>2016-12-11T09:11:21.000Z</updated>
    
    <content type="html"><![CDATA[<p>instaBTBU Promotional cards<br><a id="more"></a></p>
<p><img src="/images/instabtbu.png" alt=""></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;instaBTBU Promotional cards&lt;br&gt;
    
    </summary>
    
    
      <category term="instaBTBU" scheme="https://lhy.io/tags/instaBTBU/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://lhy.io/hello-world/"/>
    <id>https://lhy.io/hello-world/</id>
    <published>2015-06-01T07:37:28.000Z</published>
    <updated>2016-12-27T16:16:01.000Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="external">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="external">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="external">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="external">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><a id="more"></a>
<h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo new <span class="string">"My New Post"</span></div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="external">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo server</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="external">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo generate</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="external">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">$ hexo deploy</div></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="external">Deployment</a></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;
    
    </summary>
    
    
  </entry>
  
</feed>
